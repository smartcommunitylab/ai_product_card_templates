{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload input data to MinIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datalake\n",
      "ipzs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                    #endpoint_url='http://127.0.0.1:61403',\n",
    "                    #endpoint_url='http://127.0.0.1:30080',\n",
    "                    endpoint_url='https://minio-api.digitalhub-test.smartcommunitylab.it/',\n",
    "                    aws_access_key_id='minio',\n",
    "                    aws_secret_access_key='digitalhub-test',\n",
    "                    aws_session_token=None,\n",
    "                    config=boto3.session.Config(signature_version='s3v4'))\n",
    "s3.buckets.all()\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipzs_bucket = s3.Bucket(\"ipzs\")\n",
    "input_folder = \"/home/albana/Desktop/Projects/AIxPA/ai_product_card_templates/document_classification_model/fasttext/ipzs\"\n",
    "years = [\"2021\"]\n",
    "\n",
    "for year in years:\n",
    "    for root, subfolders, files in os.walk(input_folder + \"/\" + year):\n",
    "        for item in files:\n",
    "            if item.endswith(\".json\") or item.endswith(\".csv\"):\n",
    "                fileNamePath = str(os.path.join(root,item))\n",
    "                ipzs_bucket.upload_file(fileNamePath, fileNamePath.replace(input_folder + \"/\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, subfolders, files in os.walk(input_folder):\n",
    "    for item in files:\n",
    "        if item.startswith(\".DS\"):\n",
    "            fileNamePath = str(os.path.join(root,item))\n",
    "            print(fileNamePath)\n",
    "            os.remove(fileNamePath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure MLRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlrun'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlrun\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlrun'"
     ]
    }
   ],
   "source": [
    "import mlrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path of MLRun API running on Minikube\n",
    "#mlrun.set_environment(\"http://127.0.0.1:30070\")\n",
    "mlrun.set_environment(\"http://localhost:8060\")\n",
    "#set path of MLRun API running ok Kubernetes\n",
    "#mlrun.set_environment(\"https://mlrun-api.digitalhub-test.smartcommunitylab.it\", username=\"digitalhub-dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlrun.get_secret_or_env(\"MLRUN_DBPATH\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project = mlrun.new_project(\"document-classification\", context=\"./\", overwrite=True, init_git=False, user_project=False)\n",
    "project = mlrun.get_or_create_project(\"text-classification-fasttext3\", context=\"./\", init_git=False, user_project=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the pre-processing function and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_fn = project.set_function(\n",
    "    name=\"pre-processing\",\n",
    "    func=\"01-preprocessing_handlers.py\",\n",
    "    handler=\"parse_ipzs\",\n",
    "    kind=\"job\",\n",
    "    image=\"mlrun/mlrun\", #includes sklearn, pandas, numpy\n",
    "    #requirements=[] #list or path to a requirements.txt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_run = project.run_function(\n",
    "    \"pre-processing\",\n",
    "    #local=False,\n",
    "    params={\"bucket_name\": \"ipzs\", \"idPrefix\": \"ipzs-\", \"limit\": 10, \"max_documents\": 250},\n",
    "    outputs=[\"preprocessed_data\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preproc_run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpreproc_run\u001b[49m\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessed_data\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preproc_run' is not defined"
     ]
    }
   ],
   "source": [
    "preproc_run.outputs[\"preprocessed_data\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the parsing function and run it\n",
    "\n",
    "**NOTE**: building/auto-building images does not work on ARM because the resulting images are for ARM but AMD images are required. Manually building images and loading them on DockerHub is the current workaround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image has been built with:\n",
    "# docker build -t classification-parsing:latest -<<EOF\n",
    "# FROM mlrun/mlrun:1.2.1\n",
    "# RUN pip install tqdm==4.61.1\n",
    "# RUN pip install requests==2.25.1\n",
    "# RUN pip install stanza==1.4.2\n",
    "# EOF\n",
    "parsing_fn = project.set_function(\n",
    "    name=\"parsing\",\n",
    "    func=\"02-parsing_handlers.py\",\n",
    "    handler=\"parse\",\n",
    "    kind=\"job\",\n",
    "    image=\"ertomaselli/classification-parsing:latest\"\n",
    ")\n",
    "\n",
    "#for VM with autobuild\n",
    "# parsing_fn = project.set_function(\n",
    "#     name=\"parsing\",\n",
    "#     func=\"02-parsing_handlers.py\",\n",
    "#     handler=\"parse\",\n",
    "#     kind=\"job\",\n",
    "#     image=\"mlrun/mlrun\",\n",
    "#     requirements=[\"tqdm==4.61.1\", \"requests==2.25.1\", \"stanza==1.4.2\"] #list or path to a requirements.txt\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsing_run = project.run_function(\n",
    "    \"parsing\",\n",
    "    inputs={\"input_file\": preproc_run.outputs[\"preprocessed_data\"]},\n",
    "    params={\"tint_url\": None}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsing_run.outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the function that extracts test sets and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracting_fn = project.set_function(\n",
    "    name=\"extracting_test\",\n",
    "    func=\"03-extracting_test_handlers.py\",\n",
    "    handler=\"extract_test_sets\",\n",
    "    kind=\"job\",\n",
    "    image=\"mlrun/mlrun\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracting_run = project.run_function(\n",
    "    \"extracting_test\",\n",
    "    inputs={\"input_file\": preproc_run.outputs[\"preprocessed_data\"], \"tint_files\": parsing_run.outputs[\"tint_files\"]},\n",
    "    params={\"testRatio\": 0.2, \"devRatio\": 0.2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracting_run.outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the function for saving data and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_fn = project.set_function(\n",
    "    name=\"saving_data\",\n",
    "    func=\"04-saving_data_handlers.py\",\n",
    "    handler=\"save_data\",\n",
    "    kind=\"job\",\n",
    "    image=\"ertomaselli/classification-parsing:latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_run = project.run_function(\n",
    "    \"saving_data\",\n",
    "    inputs={\"input_file\": preproc_run.outputs[\"preprocessed_data\"],\n",
    "            \"test_list_file\": extracting_run.outputs[\"testlist\"],\n",
    "            \"dev_list_file\": extracting_run.outputs[\"devlist\"],\n",
    "            \"tint_files\": parsing_run.outputs[\"tint_files\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_run.outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the filtering function and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering_fn = project.set_function(\n",
    "    name=\"filtering\",\n",
    "    func=\"05-filtering_handlers.py\",\n",
    "    handler=\"filter\",\n",
    "    kind=\"job\",\n",
    "    image=\"ertomaselli/classification-parsing:latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering_run = project.run_function(\n",
    "    \"filtering\",\n",
    "    inputs={\"complete_json_file\": saving_run.outputs[\"complete\"]},\n",
    "    params={\"minFreq\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering_run.outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the training function and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image has been built with:\n",
    "# docker build -t classification-training:latest -<<EOF\n",
    "# FROM mlrun/mlrun:1.2.1\n",
    "# RUN apt-get update\n",
    "# RUN apt-get install build-essential -y\n",
    "# RUN pip install fasttext\n",
    "# EOF\n",
    "training_fn = project.set_function(\n",
    "    name=\"training\",\n",
    "    func=\"training_handlers.py\",\n",
    "    handler=\"train\",\n",
    "    kind=\"job\",\n",
    "    image=\"ertomaselli/classification-training:latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_run = project.run_function(\n",
    "    \"training\",\n",
    "    inputs={\"training_files\": filtering_run.outputs[\"filtering_files\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_run.outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the evaluation function and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_fn = project.set_function(\n",
    "    name=\"evaluation\",\n",
    "    func=\"06-evaluation_handlers.py\",\n",
    "    handler=\"evaluate\",\n",
    "    kind=\"job\",\n",
    "    image=\"mlrun/mlrun\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_run = project.run_function(\n",
    "    \"evaluation\",\n",
    "    inputs={\"pred_files\": training_run.outputs[\"results\"], \"gold_files\": filtering_run.outputs[\"filtering_files\"]},\n",
    "    params={\"show_cm\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_run.outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and run a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_workflow(\n",
    "    \"classification\",\n",
    "    workflow_path=\"classification_pipeline.py\",\n",
    "    engine=\"kfp\",\n",
    "    handler=\"classification_pipeline\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = project.run(\n",
    "    name=\"classification\",\n",
    "    # arguments={\n",
    "    #     \"data_format\": \"parse_ipzs\",\n",
    "    #     \"bucket_name\": \"ipzs\", \"idPrefix\": \"ipzs-\", \"limit\": 10, \"max_documents\": 100,\n",
    "    #     \"tint_url\": None,\n",
    "    #     \"testRatio\": 0.2, \"devRatio\": 0.2\n",
    "    # }, \n",
    "    watch=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_fn = mlrun.new_function(\"model-server\", kind=\"serving\", image=\"ertomaselli/classification-tqdm-stanza-fasttext:latest\", project=\"document-classification\")\n",
    "\n",
    "#model_path = training_run.outputs[\"allTokens_unfiltered_model\"]\n",
    "model_path = \"./allTokens_unfiltered_model.bin\" #test with single local model\n",
    "\n",
    "# set the topology/router and add models\n",
    "graph = serving_fn.set_topology(\"router\")\n",
    "serving_fn.add_model(\"allTokens_unfiltered_model\", model_path=model_path, class_name=\"model_serving.ClassifierModel\")\n",
    "\n",
    "project.set_function(serving_fn)\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test function locally\n",
    "server = serving_fn.to_mock_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/Users/erica/document-classification/input-folder/atti_materie_SG_nov2021.csv\"\n",
    "text = \"Norme in materia tributaria, di previdenza, di assunzioni nella pubblica amministrazione ed altre disposizioni urgenti.\"\n",
    "\n",
    "server.test(\"/v2/models/allTokens_unfiltered_model/infer\", body={\"inputs\": [csv_path, text]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serving_fn.deploy()\n",
    "mlrun.deploy_function(serving_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "343bb70f12b44ae63a03bfef0b5497cce79e4f4e445694908433dc5fcef2cb28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
