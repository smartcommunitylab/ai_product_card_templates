{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47283bed-9f47-4a2c-a059-f1adbab2bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2faf41-b8b5-4233-84f6-7bf8f6241a6f",
   "metadata": {},
   "source": [
    "# Create the 'LLM chatbot' AIPC project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095725e7-4836-4461-9cd5-d0fb485ca238",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = mlrun.get_or_create_project(\n",
    "    name=\"llm-text2seq-aipc\",\n",
    "    context=\"./\",\n",
    "    parameters={\n",
    "        \"source\": \"https://github.com/smartcommunitylab/ai_product_card_templates/tree/main/aipc_examples/text2seq\",\n",
    "    },\n",
    ")\n",
    "secrets = {\"MINIO_URL\": \"\", \"MINIO_AK\": \"\", \"MINIO_SK\": \"\", \"WANDB_ENTITY\": \"\", \"WANDB_PROJECT\": \"\", \"WANDB_API_KEY\": \"\", \"HF_TOKEN\": \"\"}\n",
    "project.set_secrets(secrets=secrets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49043f45-be5f-43bd-b1a2-b0430ccc051c",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e626844f-c0ee-444c-a9dd-e96725df2f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "fn = project.set_function(\n",
    "    image=\"mlrun/mlrun-gpu\",\n",
    "    name=\"training\",\n",
    "    func='functions/training.py',\n",
    "    handler='training',\n",
    "    kind=\"job\",\n",
    "    requirements = [\"peft\", \"transformers\", \"datasets\", \"bitsandbytes\", \"trl\", \"accelerate\", \"wandb\"]\n",
    ")\n",
    "project.build_function(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c3cf10-001d-4ace-b54e-69eb00445e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client\n",
    "tol = [\n",
    "    client.V1Toleration(\n",
    "        key='virtual-kubelet.io/provider',\n",
    "        operator='Equal',\n",
    "        value=\"k8sgpu\",\n",
    "        effect='NoExecute',\n",
    "    ),\n",
    "    client.V1Toleration(\n",
    "        key='node.kubernetes.io/network-unavailable',\n",
    "        operator='Exists',\n",
    "        effect='NoSchedule',\n",
    "    )\n",
    "]\n",
    "fn.with_node_selection(tolerations=tol,node_selector={\"kubernetes.io/hostname\": \"k8s.gpu\"})\n",
    "fn.with_limits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee85a6c0-33e2-449b-8e41-809c0adf4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfad182-9e59-4c62-85b1-2dc4eb8f66ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Serving function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95553f63-747a-4e85-bc4c-51d2e8184ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Serving function\n",
    "serving_fn = mlrun.code_to_function(\n",
    "    \"serving-llama2\", \n",
    "    filename=\"serve2.py\", \n",
    "    kind=\"serving\", \n",
    "    image=\"mlrun/mlrun-gpu\",\n",
    ")\n",
    "serving_fn.spec.build.commands = [\n",
    "    \"pip install torch peft transformers bitsandbytes accelerate minio\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d012765-388e-416e-a547-ae5d65e8ad27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a010d7-2d9f-4d59-b82c-e5db021d366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define resources\n",
    "serving_fn.spec.replicas = 1\n",
    "from kubernetes import client\n",
    "tol = [\n",
    "    client.V1Toleration(\n",
    "        key='nvidia.com/gpu',\n",
    "        operator='Equal',\n",
    "        value='a100',\n",
    "        effect='NoSchedule',\n",
    "    )\n",
    "]\n",
    "serving_fn.with_node_selection(tolerations=tol)\n",
    "serving_fn.with_limits(gpus=1,mem=\"200G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2d64ae-0e33-45d6-aebb-660330145fba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serving_fn.add_model(\n",
    "    \"llama2\",\n",
    "    model_path=\" \",\n",
    "    model_name=\"meta-llama/Llama-2-7b-hf\",\n",
    "    adapter_path='checkpoint-400',\n",
    "    class_name=\"ChatBot\"\n",
    ")\n",
    "myproject.deploy_function(serving_fn)\n",
    "myproject.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbd0d20-f5b4-4a3f-b95c-8280bf9b10f0",
   "metadata": {},
   "source": [
    "## Chat with the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d117fb-aeb3-4301-b69f-47feb24f0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"'You are a powerful text-to-SQL model. Your job is to answer questions about a database. \\\n",
    "You are given a question and context regarding one or more tables. \\\n",
    "    \\n\\nYou must output the SQL query that answers the question.\\\n",
    "    \\n\\n### Input:\\nWho won the points classification when the teams classification winner was Lampre-Farnese? \\\n",
    "\\n\\n### Context:\\nCREATE TABLE table_28092844_16 (points_classification_klasyfikacja_punktowa VARCHAR, teams_classification VARCHAR)\\\n",
    "\\n\\n### Response:\\n\"\n",
    "skip_special_tokens=False\n",
    "max_new_tokens=250\n",
    "do_sample=False\n",
    "sample = {\n",
    "    \"row\": text, \n",
    "    \"skip_special_tokens\": skip_special_tokens, \n",
    "    \"max_new_tokens\": max_new_tokens,\n",
    "    \"do_sample\": do_sample\n",
    "}\n",
    "response = serving_fn.invoke(path=f\"/v2/models/llama2/infer\", body={\"inputs\": [sample]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b4ed2d-1276-4ffa-a1a1-00baef91c1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
